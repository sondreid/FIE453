df_subset <- merged %>%
filter(PERMNO %in% permno$PERMNO)
remove_all_zero_columns <- function(df) {
columns <- df %>% apply(MARGIN = 2, FUN = function(x) all(is.na(x)))
return (columns)
}
remove_all_zero_columns(df_subset)
test <- remove_all_zero_columns(df_subset)
gc()
test %>% typeof()
test$rownames
rownames(test
)
test %>% as.data.frame()
test %>% as_tibble(
)
test
remove_all_zero_columns <- function(df) {
columns <- df %>% apply(MARGIN = 2, FUN = function(x) all(is.na(x))) %>%
as.data.frame()
filter(. == FALSE) %>%
rownames()
out_df <- df %>% select(columns)
return (out_df)
}
test <- remove_all_zero_columns(df_subset)
View(df_subset)
df_subset$RET ==
fe
df_subset$PRC[2] == (df_subset$PRC[1]*df_subset$RET[2])
(df_subset$PRC[1]*df_subset$RET[2])
df_subset$PRC[1]
df_subset$PRC[2]
df_subset$PRC[1] * (1+df_subset$RET[2])
df_subset$PRC[1] * (1+df_subset$RET[1])
df_subset$PRC[1] * (1+df_subset$RET[1])
remove_all_zero_columns <- function(df) {
columns <- df %>% apply(MARGIN = 2, FUN = function(x) all(is.na(x))) %>%
as.data.frame()
filter(. == FALSE) %>%
rownames()
out_df <- df %>% select(columns)
return (out_df)
}
test <- remove_all_zero_columns(df_subset)
remove_all_zero_columns <- function(df) {
columns <- df %>% apply(MARGIN = 2, FUN = function(x) all(is.na(x))) %>%
as.data.frame() %>%
filter(. == FALSE) %>%
rownames()
out_df <- df %>% select(columns)
return (out_df)
}
test <- remove_all_zero_columns(df_subset)
test
View(test)
remove_all_zero_columns <- function(df) {
columns <- df %>% apply(MARGIN = 2, FUN = function(x) all(is.na(x))) %>%
as.data.frame() %>%
filter(. == FALSE) %>%
rownames()
out_df <- df %>% select(all_of(columns))
return (out_df)
}
test <- remove_all_zero_columns(df_subset)
test
View(test)
############################ ENE452 final paper ##############################
##############################################################################
########################### DATA EXPLORATION SCRIPT ###########################
## Libaries
library(tidyverse)
library(magrittr)
library(caret)
library(tsibble)
library(Keras)
library(readr)
library(kableExtra)
load("data/merged.Rdata")
#read_compustat_crsp()
load(file = "cached_data/column_names.Rdata")
merged %>% colnames()
merged %>% colnames() %>% filter("loq" %in%)
merged %>% colnames() %>% %in% "wdpg"
merged %>% colnames()  %in% "wdpg"
merged %>% colnames()  %in% "tiiq
"
"gldq" %in% merged %>% colnames()
merged %>% colnames() %>% %in% "wdpg"
## Libaries
library(tidyverse)
library(magrittr)
library(caret)
library(tsibble)
library(Keras)
library(readr)
library(kableExtra)
library(leaps)
load("data/merged.Rdata")
read_compustat_crsp <- function() {
crsp_df <- read_csv("data/crsp.csv")
compustat_df <- read_csv("data/compustat.csv")
compustat_columns <- colnames(compustat_df) %>% as_tibble()
crsp_columns <- colnames(crsp_df) %>% as_tibble()
save(compustat_columns, crsp_columns, file = "cached_data/column_names.Rdata")
}
#read_compustat_crsp()
load(file = "cached_data/column_names.Rdata")
# Subset of 100 companies
permno <- merged %>%
select(PERMNO) %>%
unique() %>%
head(1000)
remove_zero_and_NA <- function(df, ratio) {
#'
#'@ratio: ratio of NA's which a column of data cannot exceed
out_df <- df
df[is.na(df)] <- 0
cols <- df %>% apply(MARGIN = 2, function(x) sum(x==0, na.rm = T)/length(x))
cols <- cols[cols < ratio] %>% as.data.frame() %>% rownames()
return (
out_df %>% select(cols)
)
}
###### EITHER FULLY MERGED SET OR A REDUCED DATASET
# Filtering the data frame containing only the 100 first companies
df_reduced <- merged %>%
filter(PERMNO %in% permno$PERMNO) %>%
remove_zero_and_NA(0.3) %>%
filter(!is.na(RETX))
perform_train_validate_split <- function(df, train_ratio = 0.6, test_ratio = 0.5) {
#' @Description: Ensures an equal amount of companies in each set
#'
#' @df:    The dataframe to be split
#' @ratio: Ratio of training data, (validation and test set to equal length)
#' @return: A list of three dataframes: training, validation and test sets
set.seed(123)
all_companies <- df$PERMNO %>% unique()
train_indices <- sample(1:length(all_companies), floor(length(all_companies)* train_ratio))
train_companies <- all_companies[train_indices]
val_test_companies <- all_companies[-companies_indices]
val_indices <- sample(1:length(val_test_companies), floor(length(val_test_companies)* test_ratio))
val_companies <- all_companies[val_indices]
test_companies <- all_companies[-c(val_indices, train_indices)]
train_df <- df %>% filter(PERMNO %in% train_companies)
val_df <- df %>% filter(PERMNO %in% val_companies)
test_df <- df %>% filter(PERMNO %in% test_companies)
return (
list(train_df, val_df, test_df)
)
}
find_company_observations <- function(df, minimum_obserations) {
#'
#' @description: Finds companies
all_companies <- df$PERMNO %>% unique()
df %<>% group_by(PERMNO) %>%
summarise(count = n()) %>%
ungroup() %>%
filter(count < minimum_obserations) %>%
arrange(desc(count))
return(df)
}
low_observation_count_companies <- find_company_observations(df_reduced, 50)
df_reduced <- df_reduced %>% anti_join(companies) # Cut companies with fewer than 50 observations (they cannot be reliably predicted)
df_reduced <- df_reduced %>% anti_join(low_observation_count_companies) # Cut companies with fewer than 50 observations (they cannot be reliably predicted)
train_validation_test_reduced <- perform_train_validate_split(df_reduced, train_ratio = 0.6, test_ratio = 0.5)
list = list(1,2,3)
list[-c(1,2)]
list[-c(1,3)]
list = list(4,5,6)
list[-c(1,3)]
list[-c(1,3)]
list[-c(1,3)]
perform_train_validate_split <- function(df, train_ratio = 0.6, test_ratio = 0.5) {
#' @Description: Ensures an equal amount of companies in each set
#'
#' @df:    The dataframe to be split
#' @ratio: Ratio of training data, (validation and test set to equal length)
#' @return: A list of three dataframes: training, validation and test sets
set.seed(123)
all_companies <- df$PERMNO %>% unique()
train_indices <- sample(1:length(all_companies), floor(length(all_companies)* train_ratio))
train_companies <- all_companies[train_indices]
val_test_companies <- all_companies[-train_indices]
val_indices <- sample(1:length(val_test_companies), floor(length(val_test_companies)* test_ratio))
val_companies <- all_companies[val_indices]
test_companies <- all_companies[-c(val_indices, train_indices)]
train_df <- df %>% filter(PERMNO %in% train_companies)
val_df <- df %>% filter(PERMNO %in% val_companies)
test_df <- df %>% filter(PERMNO %in% test_companies)
return (
list(train_df, val_df, test_df)
)
}
find_company_observations <- function(df, minimum_obserations) {
#'
#' @description: Finds companies
all_companies <- df$PERMNO %>% unique()
df %<>% group_by(PERMNO) %>%
summarise(count = n()) %>%
ungroup() %>%
filter(count < minimum_obserations) %>%
arrange(desc(count))
return(df)
}
low_observation_count_companies <- find_company_observations(df_reduced, 50)
df_reduced <- df_reduced %>% anti_join(low_observation_count_companies) # Cut companies with fewer than 50 observations (they cannot be reliably predicted)
train_validation_test_reduced <- perform_train_validate_split(df_reduced, train_ratio = 0.6, test_ratio = 0.5)
train_df_reduced <- train_validation_test_reduced[[1]]
validation_df_reduced <- train_validation_test_reduced[[2]]
test_df_reduced <- train_validation_test_reduced[[3]]
1 == 2 == 3
(train_df_reduced %>% nrow()) + (validation_df_reduced %>% nrow()) + (test_df_reduced %>% nrow())
# Check for similar rows
test_df_reduced %>% inner_join(train_df_reduced)
# Check for similar rows
test_df_reduced %>% inner_join(train_df_reduced, by = "PERMNO")
# Check for similar rows
test_df_reduced %>% inner_join(train_df_reduced, by = "PERMNO") %>%
inner_join(validation_df_reduced, by = "PERMNO")
# Check for similar rows
test_df_reduced %>% inner_join(train_df_reduced, by = "PERMNO") %>%
inner_join(validation_df_reduced, by = "PERMNO") %>% nrow()
View(test_df_reduced)
(train_df_reduced$PERMNO %>% unique() %>% length()) + (validation_df_reduced$PERMNO %>% unique() %>% length()) + (test_df_reduced$PERMNO %>% unique() %>% length())
(train_df_reduced$PERMNO %>% unique() %>% length()) + (validation_df_reduced$PERMNO %>% unique() %>% length()) + (test_df_reduced$PERMNO %>% unique() %>% length()) ==
df_reduced$PERMNO %>% unique() %>% length()
df_reduced$PERMNO %>% unique() %>% length()
# Check for similar rows
test_df_reduced %>% left_join(train_df_reduced, by = "PERMNO") %>%
left_join(validation_df_reduced, by = "PERMNO") %>% nrow()
# Check for similar rows
test_df_reduced %>% anti_join(train_df_reduced, by = "PERMNO") %>%
anti_join(validation_df_reduced, by = "PERMNO") %>% nrow()
test_df_reduced %>% nrow()
perform_train_test_split <- function(df, train_ratio = 0.6, test_ratio = 0.5) {
#' @Description: Ensures an equal amount of companies in each set
#'
#' @df:    The dataframe to be split
#' @ratio: Ratio of training data, (validation and test set to equal length)
#' @return: A list of three dataframes: training, validation and test sets
set.seed(123)
all_companies <- df$PERMNO %>% unique()
train_indices <- sample(1:length(all_companies), floor(length(all_companies)* train_ratio))
train_companies <- all_companies[train_indices]
val_test_companies <- all_companies[-train_indices]
val_indices <- sample(1:length(val_test_companies), floor(length(val_test_companies)* test_ratio))
val_companies <- all_companies[val_indices]
test_companies <- all_companies[-c(val_indices, train_indices)]
train_df <- df %>% filter(PERMNO == train_companies)
val_df <- df %>% filter(PERMNO == val_companies)
test_df <- df %>% filter(PERMNO == test_companies)
return (
list(train_df, val_df, test_df)
)
}
train_validation_test_reduced <- perform_train_validate_split(df_reduced, train_ratio = 0.6, test_ratio = 0.5)
train_df_reduced <- train_validation_test_reduced[[1]]
validation_df_reduced <- train_validation_test_reduced[[2]]
test_df_reduced <- train_validation_test_reduced[[3]]
(train_df_reduced %>% nrow()) + (validation_df_reduced %>% nrow()) + (test_df_reduced %>% nrow())
(train_df_reduced$PERMNO %>% unique() %>% length()) + (validation_df_reduced$PERMNO %>% unique() %>% length()) + (test_df_reduced$PERMNO %>% unique() %>% length()) ==
df_reduced$PERMNO %>% unique() %>% length()
df_reduced$PERMNO %>% unique() %>% length()
(train_df_reduced$PERMNO %>% unique() %>% length()) + (validation_df_reduced$PERMNO %>% unique() %>% length()) + (test_df_reduced$PERMNO %>% unique() %>% length())
perform_train_test_split <- function(df, train_ratio = 0.8) {
#' @Description: Ensures an equal amount of companies in each set
#'
#' @df:    The dataframe to be split
#' @ratio: Ratio of training data, (validation and test set to equal length)
#' @return: A list of three dataframes: training, validation and test sets
set.seed(123)
all_companies <- df$PERMNO %>% unique()
train_indices <- sample(1:length(all_companies), floor(length(all_companies)* train_ratio))
train_companies <- all_companies[train_indices]
test_companies <- all_companies[-train_indices]
train_df <- df %>% filter(PERMNO == train_companies)
test_df <- df %>% filter(PERMNO == test_companies)
return (
list(train_df, test_df)
)
}
train_df_0.8 <- perform_train_test_split(df_reduced)
train_test_df_0.8 <- perform_train_test_split(df_reduced)
train_df_0.8 <- train_test_df_0.8[[1]]
test_df_0.8 <- train_test_df_0.8[[2]]
View(test_df_0.8)
perform_train_test_split <- function(df, train_ratio = 0.8) {
#' @Description: Ensures an equal amount of companies in each set
#'
#' @df:    The dataframe to be split
#' @ratio: Ratio of training data, (validation and test set to equal length)
#' @return: A list of three dataframes: training, validation and test sets
set.seed(123)
all_companies <- df$PERMNO %>% unique()
train_indices <- sample(1:length(all_companies), floor(length(all_companies)* train_ratio))
train_companies <- all_companies[train_indices]
test_companies <- all_companies[-train_indices]
train_sample <- df %>% filter(PERMNO %in% train_companies)
test_sample <- df %>% filter(PERMNO %in% test_companies)
return (
list(train_sample, test_df)
)
}
perform_train_test_split <- function(df, train_ratio = 0.8) {
#' @Description: Ensures an equal amount of companies in each set
#'
#' @df:    The dataframe to be split
#' @ratio: Ratio of training data, (validation and test set to equal length)
#' @return: A list of three dataframes: training, validation and test sets
set.seed(123)
all_companies <- df$PERMNO %>% unique()
train_indices <- sample(1:length(all_companies), floor(length(all_companies)* train_ratio))
train_companies <- all_companies[train_indices]
test_companies <- all_companies[-train_indices]
train_sample <- df %>% filter(PERMNO %in% train_companies)
test_sample  <- df %>% filter(PERMNO %in% test_companies)
return (
list(train_sample, test_sample)
)
}
train_test_df_0.8 <- perform_train_test_split(df_reduced)
train_df_0.8 <- train_test_df_0.8[[1]]
test_df_0.8 <- train_test_df_0.8[[2]]
(train_df_0.8 %>% nrow())  + (test_df_0.8 %>% nrow())
perform_train_validate_split <- function(df, train_ratio = 0.6, test_ratio = 0.5) {
#' @Description: Ensures an equal amount of companies in each set
#'
#' @df:    The dataframe to be split
#' @ratio: Ratio of training data, (validation and test set to equal length)
#' @return: A list of three dataframes: training, validation and test sets
set.seed(13231)
all_companies <- df$PERMNO %>% unique()
train_indices <- sample(1:length(all_companies), floor(length(all_companies)* train_ratio))
train_companies <- all_companies[train_indices]
val_test_companies <- all_companies[-train_indices]
val_indices <- sample(1:length(val_test_companies), floor(length(val_test_companies)* test_ratio))
val_companies <- all_companies[val_indices]
test_companies <- all_companies[-c(val_indices, train_indices)]
train_sample <- df %>% filter(PERMNO %in% train_companies)
val_sample <- df %>% filter(PERMNO %in% val_companies)
test_sample <- df %>% filter(PERMNO %in% test_companies)
return (
list(train_sample, val_sample, test_sample)
)
}
low_observation_count_companies <- find_company_observations(df_reduced, 50)
df_reduced <- df_reduced %>% anti_join(low_observation_count_companies) # Cut companies with fewer than 50 observations (they cannot be reliably predicted)
train_validation_test_reduced <- perform_train_validate_split(df_reduced, train_ratio = 0.6, test_ratio = 0.5)
train_df_reduced <- train_validation_test_reduced[[1]]
validation_df_reduced <- train_validation_test_reduced[[2]]
test_df_reduced <- train_validation_test_reduced[[3]]
(train_df_reduced %>% nrow()) + (validation_df_reduced %>% nrow()) + (test_df_reduced %>% nrow())
# Train and
train_test_df_0.8 <- perform_train_test_split(df_reduced)
train_df_0.8 <- train_test_df_0.8[[1]]
test_df_0.8 <- train_test_df_0.8[[2]]
(train_df_0.8 %>% nrow())  + (test_df_0.8 %>% nrow())
train_test_reduced <- perform_train_test_split(df_reduced, train_ratio = 0.8)
train_test_reduced <- perform_train_test_split(df_reduced, train_ratio = 0.8)
train_df_reduced <- train_test_reduced[[1]]
test_df_reduced <- train_test_reduced[[2]]
# Check for similar rows
test_df_reduced %>% inner_join(train_df_reduced, by = "PERMNO") %>% nrow()
# Libraries --------------------------------------------------------------------
library(tidyverse)
library(magrittr)
library(tidymodels)
# Set WD -----------------------------------------------------------------------
#setwd("~/OneDrive - Norges HandelshÃ¸yskole/MASTER/FIE453/FinalExam/FIE453/Final Paper")
# Load and read data -----------------------------------------------------------
load("data/merged.Rdata")
company_names_df <- read.csv(file = "data/names.csv")
feature_names_df <- read.delim(file = "data/compustat-fields.txt")
company_names_df %<>% rename_with(tolower)
feature_names_df %<>% rename_with(tolower)
merged %<>% rename_with(tolower)
# Subset of 100 companies ------------------------------------------------------
permno_top <- (merged %>%
select(permno) %>%
unique() %>%
head(1000))$permno
df <- merged %>% filter(permno %in% permno_top)
company_names_df <- read.csv(file = "data/names.csv")
# Load and read data -----------------------------------------------------------
load("data/merged.Rdata")
#company_names_df <- read.csv(file = "data/names.csv")
#feature_names_df <- read.delim(file = "data/compustat-fields.txt")
#company_names_df %<>% rename_with(tolower)
#feature_names_df %<>% rename_with(tolower)
merged %<>% rename_with(tolower)
# Subset of 100 companies ------------------------------------------------------
permno_top <- (merged %>%
select(permno) %>%
unique() %>%
head(1000))$permno
df <- merged %>% filter(permno %in% permno_top)
df$permno %>% unique() %>% length()
# Subset of 100 companies ------------------------------------------------------
permno_top <- (merged %>%
select(permno) %>%
unique() %>%
head(1000))$permno
df_reduced <- merged %>% filter(permno %in% permno_top)
# Feature selection functions --------------------------------------------------
remove_cols_only_zero_and_NA <- function(df, print_removed_cols = F) {
#'@description Function that removes columns containing only zeros and NAs
#'
#'@param df    Passing a data frame
#'@param print_removed_cols True if user want to print removed columns
#'@return      Data frame without columns that containing only zeros and NAs
cols <- df %>% apply(MARGIN = 2, function(x) (sum(x==0, na.rm = T) + sum(is.na(x)))/length(x))
cols <- cols[cols == 1] %>% as.data.frame() %>% rownames()
if(print_removed_cols) cat("Columns removed: ", cols, "\n\n")
return (df %>% select(-cols))
}
remove_NA <- function(df, ratio, print_removed_cols = F){
#'@description Function that removes columns containing NAs beyond a given
#'             ratio
#'
#'@param df    Passing a data frame
#'@param ratio Passing a upper limit NA ratio
#'@param print_removed_cols True if user want to print removed columns
#'@return      Data frame without columns containing NAs beyond given ratio
cols <- df %>% apply(MARGIN = 2, function(x) sum(is.na(x))/length(x))
cols <- cols[cols >= ratio] %>% as.data.frame() %>% rownames()
if(print_removed_cols) cat("Columns removed: ", cols, "\n\n")
return(df %>% select(-cols))
}
remove_nzv <- function(df, print_removed_cols = F){
#'@description Function that removes near zero variance columns
#'
#'@param df    Passing a data frame
#'@param print_removed_cols True if user want to print removed columns
#'@return      Data frame without columns near zero variance columns
rec <- recipe(retx ~ .,
data = df)
cols <- (rec %>%
step_nzv(all_predictors()) %>%
prep(df) %>%
tidy(number = 1))$terms
if(print_removed_cols) cat("Columns removed: ", cols, "\n\n")
return(df %>% select(-cols))
}
remove_hcv <- function(df, threshold = 0.9, print_removed_cols = F){
#'@description Function that removes highly correlated features
#'
#'@param df    Passing a data frame
#'@param treshold Correlation beneath this treshold
#'@param print_removed_cols True if user want to print removed columns
#'@return      Data frame without highly correlated features
numeric_cols <- df %>% lapply(is.numeric) %>% unlist()
rec <- recipe(retx ~ .,
data = df[numeric_cols])
cols <- (rec %>%
step_corr(all_predictors(),
threshold = threshold) %>%
prep(df[numeric_cols]) %>%
tidy(number = 1))$terms
if(print_removed_cols) cat("Columns removed: ", cols, "\n\n")
return(df %>% select(-cols))
}
replace_NA_with_mean <- function(df, print_replaced_cols = F){
#'@description Function that replaces NA with column means
#'
#'@param df    Passing a data frame
#'@param print_replaced_cols True if user want to print replaced columns
#'@return      Data frame NA-replaced column means
na_cols <- df %>% apply(MARGIN = 2, function(x) any(is.na(x)))
numeric_cols <- df[na_cols] %>% lapply(is.numeric) %>% unlist()
col_means <- df[na_cols] %>% colMeans(na.rm = T)
col_names <- col_means %>% names()
for (col in col_names){
df[col] <- df[col][[1]] %>% replace_na(col_means[col])
}
if(print_replaced_cols) cat("Columns replaced: ", col_names, "\n\n")
return(df)
}
# Testing ----------------------------------------------------------------------
df_reduced %<>%
remove_cols_only_zero_and_NA(print_removed_cols = T) %>%
remove_NA(0.2, print_removed_cols = T) %>%
remove_nzv(print_removed_cols = T) %>%
remove_hcv(0.9, print_removed_cols = T) %>%
replace_NA_with_mean(print_replaced_cols = T)
recipe
??recipe
library(tidymodels)
install.packages("recipes")
install.packages("recipes")
library(tidymodels)
install.packages("ipred")
library(tidymodels)
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
library(tidymodels)
update.packges()
update.packages()
library(tidymodels)
remove.packages("tidymodels")
remove.packages("recipes")
install.packages("tidymodels")
remove.packages("ipred")
install.packages("tidymodels")
library(tidymodels)
remove.packages("ipred")
install.packages("ipred")
library(tidymodels)
library(tidymodels)
remove.packages("ipred")
install.packages("ipred")
