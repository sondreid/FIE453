predictions_5_nn_model_ada_delta <- best_model_ada_delta %>% predict(test_df_reduced %>% dplyr::select(-retx))
grid_search_nn_model_ada_delta <- function(model, model_train_df, model_test_df,
epochs, batch_sizes, verbose) {
best_MAE <- Inf
best_model <- NA
best_history <- NA
for (epoch in epochs) {
for (batch_size in batch_sizes) {
new_model <- model %>%
compile(
loss = "mse",
optimizer = optimizer_adadelta(),
metrics = list("mean_absolute_error"))
history <- new_model %>%
fit(
x = model_train_df %>% dplyr::select(-retx),
y = model_train_df$retx,
epochs = epoch,
batch_size = batch_size,
validation_split = 0.2,
verbose = verbose,
callbacks = list(print_dot_callback, early_stop) #Print simplified dots, and stop learning when validation improvements stalls
)
c(loss, mae) %<-% (new_model %>% evaluate(model_test_df %>% dplyr::select(-retx), model_test_df$retx, verbose = 0))
if (mae < best_MAE) {
best_history <- history
best_model <- new_model
best_MAE <- mae
}
}
}
return (list(best_model, best_history))
}
best_model_ada_delta <- grid_search_nn_model_ada_delta(nn_model_5_layers_reduced, train_df_reduced, test_df_reduced,
batch_sizes = list(50, 80, 400, 1000, 10000),
epochs = list(20, 50, 70, 300),
verbose = 0)
predictions_5_nn_model_ada_delta <- best_model_ada_delta[[2]] %>% predict(test_df_reduced %>% dplyr::select(-retx))
predictions_5_nn_model_ada_delta <- best_model_ada_delta[[1]] %>% predict(test_df_reduced %>% dplyr::select(-retx))
predictions_5_nn_model_ada_delta[ , 1]
postResample(predictions_5_nn_model_ada_delta[ , 1], test_df_reduced$retx)
# Better than 0 benchmark?
make_0_benchmark(test_df_reduced)
best_model_ada_delta[[1]]
plot(best_model_ada_delta[[1]])
plot(best_model_ada_delta[[2]])
grid_search_nn_model <- function(model, model_train_df, model_test_df, learning_rates, momentums,
epochs, batch_sizes, verbose) {
best_MAE <- Inf
best_model <- NA
best_history <- NA
for (lr in learning_rates) {
for (momentum in momentums) {
for (epoch in epochs) {
for (batch_size in batch_sizes) {
new_model <- model %>%
compile(
loss = "mse",
optimizer = optimizer_sgd(
learning_rate =lr,
momentum = momentum),
metrics = list("mean_absolute_error"))
history <- new_model %>%
fit(
x = model_train_df %>% dplyr::select(-retx),
y = model_train_df$retx,
epochs = epoch,
batch_size = batch_size,
validation_split = 0.2,
verbose = verbose,
callbacks = list(print_dot_callback, early_stop) #Print simplified dots, and stop learning when validation improvements stalls
)
c(loss, mae) %<-% (new_model %>% evaluate(model_test_df %>% dplyr::select(-retx), model_test_df$retx, verbose = 0))
if (mae < best_MAE) {
best_history <- history
best_model <- new_model
best_MAE <- mae
}
}
}
}
}
return (best_model)
}
best_model <- grid_search_nn_model(nn_model_5_layers_reduced, train_df_reduced, test_df_reduced,
learning_rates = list(0.01, 0.0001),
momentums = list(0, 0.001),
batch_sizes = list(100, 500, 1500),
epochs = list(30, 100, 200, 500),
verbose = 0
)
predictions_5_nn_model <- best_model %>% predict(test_df_reduced %>% dplyr::select(-retx))
predictions_5_nn_model[ , 1]
postResample(predictions_5_nn_model[ , 1], test_df_reduced$retx)
# Better than 0 benchmark?
make_0_benchmark(test_df_reduced)
build_nn_model_5_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dense(units = 4,  activation = "relu") %>%
layer_dense(units = 2,  activation = "relu")
model <- keras_model(input, output)
return (model)
}
build_nn_model_3_layers <- function() {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8,  activation = "relu")
model <- keras_model(input, output)
return(model)
}
build_nn_model_1_layer <- function() {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_3_layers_reduced <- build_nn_model_3_layers(train_df_reduced, spec_reduced)
nn_model_5_layers_reduced <- build_nn_model_5_layers(train_df_reduced, spec_reduced)
### REDUCED DATA SET FOR TESTING
selection_data_reduced <- get_subset_of_companies_ratio(selection_data, 0.15)
# Train-Test-Split
train_test_reduced <- perform_train_test_split(selection_data_reduced,
train_ratio = 0.8)                       # Split into train and test set with seperate sets of companies
train_df_reduced <- train_test_reduced[[1]]
test_df_reduced <- train_test_reduced[[2]]
train_df_reduced %<>% dplyr::select(-permno) # Remove company numbers from training
low_observation_count_companies <- find_company_observations(test_df_all, 50)
test_df_reduced %<>% anti_join(low_observation_count_companies)                        # Cut companies with fewer than 50 observations (they cannot be reliably predicted)
save(train_df, selection_data, test_df, train_df_reduced, test_df_reduced, file = "cached_data/train_test.Rdata")
rm(merged, df_selection, df_selection_reduced) # Remove large datasets from memory
build_nn_model_5_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dense(units = 4,  activation = "relu") %>%
layer_dense(units = 2,  activation = "relu")
model <- keras_model(input, output)
return (model)
}
build_nn_model_3_layers <- function() {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8,  activation = "relu")
model <- keras_model(input, output)
return(model)
}
build_nn_model_1_layer <- function() {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_3_layers_reduced <- build_nn_model_3_layers(train_df_reduced, spec_reduced)
nn_model_5_layers_reduced <- build_nn_model_5_layers(train_df_reduced, spec_reduced)
build_nn_model_5_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dense(units = 4,  activation = "relu") %>%
layer_dense(units = 2,  activation = "relu")
model <- keras_model(input, output)
return (model)
}
build_nn_model_3_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8,  activation = "relu")
model <- keras_model(input, output)
return(model)
}
build_nn_model_1_layer <- ffunction(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_3_layers_reduced <- build_nn_model_3_layers(train_df_reduced, spec_reduced)
nn_model_5_layers_reduced <- build_nn_model_5_layers(train_df_reduced, spec_reduced)
build_nn_model_5_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dense(units = 4,  activation = "relu") %>%
layer_dense(units = 2,  activation = "relu")
model <- keras_model(input, output)
return (model)
}
build_nn_model_3_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8,  activation = "relu")
model <- keras_model(input, output)
return(model)
}
build_nn_model_1_layer <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(train_df_all %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_3_layers_reduced <- build_nn_model_3_layers(train_df_reduced, spec_reduced)
nn_model_5_layers_reduced <- build_nn_model_5_layers(train_df_reduced, spec_reduced)
build_nn_model_5_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dense(units = 4,  activation = "relu") %>%
layer_dense(units = 2,  activation = "relu")
model <- keras_model(input, output)
return (model)
}
build_nn_model_3_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8,  activation = "relu")
model <- keras_model(input, output)
return(model)
}
build_nn_model_1_layer <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_3_layers_reduced <- build_nn_model_3_layers(train_df_reduced, spec_reduced)
nn_model_5_layers_reduced <- build_nn_model_5_layers(train_df_reduced, spec_reduced)
build_nn_model_1_layer <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
build_nn_model_3_layers <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 8,  activation = "relu")
model <- keras_model(input, output)
return(model)
}
build_nn_model_1_layer <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu") %>%
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_3_layers_reduced <- build_nn_model_3_layers(train_df_reduced, spec_reduced)
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_5_layers_reduced <- build_nn_model_5_layers(train_df_reduced, spec_reduced)
build_nn_model_1_layer <- function(selected_train_df, selected_spec) {
input <- layer_input_from_dataset(selected_train_df %>% dplyr::select(-retx))
output <- input %>%
layer_dense_features(dense_features(selected_spec)) %>%
layer_dense(units = 32, activation = "relu")
model <- keras_model(input, output)
return(model)
}
nn_model_1_layer_reduced <- build_nn_model_1_layer(train_df_reduced, spec_reduced)
nn_model_3_layers_reduced <- build_nn_model_3_layers(train_df_reduced, spec_reduced)
nn_model_5_layers_reduced <- build_nn_model_5_layers(train_df_reduced, spec_reduced)
grid_search_nn_model <- function(selected_model, model_train_df, model_test_df, learning_rates, momentums,
epochs, batch_sizes, verbose) {
best_MAE <- Inf
best_model <- NA
best_history <- NA
for (lr in learning_rates) {
for (momentum in momentums) {
for (epoch in epochs) {
for (batch_size in batch_sizes) {
new_model <- selected_model %>%
compile(
loss = "mse",
optimizer = optimizer_sgd(
learning_rate =lr,
momentum = momentum),
metrics = list("mean_absolute_error"))
history <- new_model %>%
fit(
x = model_train_df %>% dplyr::select(-retx),
y = model_train_df$retx,
epochs = epoch,
batch_size = batch_size,
validation_split = 0.2,
verbose = verbose,
callbacks = list(print_dot_callback, early_stop) #Print simplified dots, and stop learning when validation improvements stalls
)
c(loss, mae) %<-% (new_model %>% evaluate(model_test_df %>% dplyr::select(-retx), model_test_df$retx, verbose = 0))
if (mae < best_MAE) {
best_history <- history
best_model <- new_model
best_MAE <- mae
}
}
}
}
}
return (best_model)
}
train_df
best_model_nn_1_layer <- grid_search_nn_model(nn_model_1_layer_reduced, train_df_reduced, test_df_reduced,
learning_rates = list(0.01, 0.0001),
momentums = list(0, 0.001),
batch_sizes = list(100, 500, 1500),
epochs = list(30, 100, 200, 500),
verbose = 0
)
predictions_1_nn_model <- best_model_nn_1_layer %>% predict(test_df_reduced %>% dplyr::select(-retx))
predictions_1_nn_model[ , 1]
postResample(predictions_1_nn_model[ , 1], test_df_reduced$retx)
best_model_nn_5_layer <- grid_search_nn_model(nn_model_5_layers_reduced, train_df, test_df_reduced,
learning_rates = list(0.01, 0.0001),
momentums = list(0, 0.001),
batch_sizes = list(100, 500, 1500),
epochs = list(30, 100, 200, 500),
verbose = 0
)
best_model_nn_3_layer <- grid_search_nn_model(nn_model_3_layers_reduced, train_df, test_df_reduced,
learning_rates = list(0.01, 0.0001),
momentums = list(0, 0.001),
batch_sizes = list(100, 500, 1500),
epochs = list(30, 100, 200, 500),
verbose = 0
)
best_model_nn_1_layer <- grid_search_nn_model(nn_model_1_layer_reduced, train_df, test_df_reduced,
learning_rates = list(0.01, 0.0001),
momentums = list(0, 0.001),
batch_sizes = list(100, 500, 1500),
epochs = list(30, 100, 200, 500),
verbose = 0
)
# Train Control
parts <- createDataPartition(train_df$retx, times = 1, p = 0.2) # 20 % of training data is used for validation (i.e, hyperparameter selection)
train_control <- trainControl(method = "cv", #Method does not matter as parts dictate 20 % validation of training set
index = parts,
verboseIter = T,
savePredictions = T,
summaryFunction = defaultSummary)
# Enable parallel processing
num_cores <- detectCores() - 3
cl <- makePSOCKcluster(num_cores) # Use most cores, or specify
registerDoParallel(cl)
# Training the GBM-model
gbm_model <- caret::train(retx ~ .,
data       = train_df,
method     = "gbm",
preProcess = c("center","scale"),
metric     = "MAE",
tuneLength   = 10,
allowParalell = T,
trControl  = train_control)
predictions_3_nn_model <- best_model %>% predict(test_df_reduced %>% dplyr::select(-retx))
predictions_3_nn_model[ , 1]
postResample(predictions_3_nn_model[ , 1], test_df_reduced$retx)
predictions_5_nn_model <- nn_model_5_layers %>% predict(test_df_all %>% dplyr::select(-retx))
predictions_5_nn_model[ , 1]
postResample(predictions_5_nn_model[ , 1], test_df_all$retx)
# Better than 0 benchmark?
make_0_benchmark(test_df)
predictions_5_nn_model <- best_model_nn_5_layer %>% predict(test_df %>% dplyr::select(-retx))
predictions_5_nn_model[ , 1]
postResample(predictions_5_nn_model[ , 1], test_df$retx)
# Better than 0 benchmark?
make_0_benchmark(test_df)
make_0_benchmark(test_df_reduced)[[3]] > postResample(predictions_5_nn_model[ , 1], test_df_reduced$retx)[[3]]
best_model_nn_3_layer <- grid_search_nn_model(nn_model_3_layers_reduced, train_df, test_df,
learning_rates = list(0.01, 0.0001),
momentums = list(0, 0.001),
batch_sizes = list(100, 500, 1500),
epochs = list(30, 100, 200, 500),
verbose = 0
)
predictions_3_nn_model <- best_model %>% predict(test_df %>% dplyr::select(-retx))
predictions_3_nn_model[ , 1]
postResample(predictions_3_nn_model[ , 1], test_df$retx)
predictions_3_nn_model <- best_model %>% predict(test_df %>% dplyr::select(-retx))
postResample(predictions_3_nn_model[ , 1], test_df$retx)
# Better than 0 benchmark?
make_0_benchmark(test_df)
predictions_5_nn_model <- best_model_nn_5_layer %>% predict(test_df %>% dplyr::select(-retx))
postResample(predictions_5_nn_model[ , 1], test_df$retx)
# Better than 0 benchmark?
make_0_benchmark(test_df)
predictions_5_nn_model[ , 1]
predictions_5_nn_model[ , 1] %>% tail(5000) %>% as_tibble() %>% tibble::view()
best_model_nn_3_layer
best_model_nn_3_layer[[1]]
grid_search_nn_model <- function(selected_model, model_train_df, model_test_df, learning_rates, momentums,
epochs, batch_sizes, verbose) {
best_MAE <- Inf
best_model <- NA
best_history <- NA
for (lr in learning_rates) {
for (momentum in momentums) {
for (epoch in epochs) {
for (batch_size in batch_sizes) {
new_model <- selected_model %>%
compile(
loss = "mse",
optimizer = optimizer_sgd(
learning_rate =lr,
momentum = momentum),
metrics = list("mean_absolute_error"))
history <- new_model %>%
fit(
x = model_train_df %>% dplyr::select(-retx),
y = model_train_df$retx,
epochs = epoch,
batch_size = batch_size,
validation_split = 0.2,
verbose = verbose,
callbacks = list(print_dot_callback, early_stop) #Print simplified dots, and stop learning when validation improvements stalls
)
c(loss, mae) %<-% (new_model %>% evaluate(model_test_df %>% dplyr::select(-retx), model_test_df$retx, verbose = 0))
if (mae < best_MAE) {
best_history <- history
best_model <- new_model
best_MAE <- mae
}
}
}
}
}
return (best_model, best_history)
}
best_model_nn_3_layer <- grid_search_nn_model(nn_model_3_layers_reduced, train_df_reduced, test_df_reduced,
learning_rates = list(0.01, 0.0001),
momentums = list(0, 0.001),
batch_sizes = list(100, 500, 1500),
epochs = list(30, 100, 200, 500),
verbose = 0
)
# Libraries --------------------------------------------------------------------
library(tidyverse)
library(magrittr)
library(tidymodels)
library(randomForest)
library(caret)
library(doParallel)
library(MLmetrics)
library(gbm)
library(PerformanceAnalytics)
library(kableExtra)
library(knitr)
library(monomvn)
library(kableExtra)
library(lubridate)
library(kknn)
library(nnet)
# Set WD -----------------------------------------------------------------------
#setwd("~/OneDrive - Norges Handelshøyskole/MASTER/FIE453/FinalExam/FIE453/Final Paper")
# Load and read data -----------------------------------------------------------
load("data/merged.Rdata")
company_names_df <- read.csv(file = "descriptions/names.csv")
feature_names_df <- read.delim(file = "descriptions/compustat-fields.txt")
company_names_df %<>% rename_with(tolower) %>% mutate(date = lubridate::ymd(date))
feature_names_df %<>% rename_with(tolower)
merged %<>% rename_with(tolower) %>% mutate(date = lubridate::ymd(date))
